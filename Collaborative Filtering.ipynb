{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "This notebook will contain the steps to create a collaborative fitering recommendation system for the anime and ratings datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "### Anime Dataset\n",
    "Let's read the anime dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
       "      <td>TV</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama째</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>Sci-Fi, Thriller</td>\n",
       "      <td>TV</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>TV</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32935</td>\n",
       "      <td>Haikyuu!!: Karasuno Koukou VS Shiratorizawa Ga...</td>\n",
       "      <td>Comedy, Drama, School, Shounen, Sports</td>\n",
       "      <td>TV</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>93351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                                               name  \\\n",
       "0      5114                   Fullmetal Alchemist: Brotherhood   \n",
       "1     28977                                           Gintama째   \n",
       "2      9253                                        Steins;Gate   \n",
       "3      9969                                      Gintama&#039;   \n",
       "4     32935  Haikyuu!!: Karasuno Koukou VS Shiratorizawa Ga...   \n",
       "\n",
       "                                               genre type  episodes  rating  \\\n",
       "0  Action, Adventure, Drama, Fantasy, Magic, Mili...   TV      64.0    9.26   \n",
       "1  Action, Comedy, Historical, Parody, Samurai, S...   TV      51.0    9.25   \n",
       "2                                   Sci-Fi, Thriller   TV      24.0    9.17   \n",
       "3  Action, Comedy, Historical, Parody, Samurai, S...   TV      51.0    9.16   \n",
       "4             Comedy, Drama, School, Shounen, Sports   TV      10.0    9.15   \n",
       "\n",
       "   members  \n",
       "0   793665  \n",
       "1   114262  \n",
       "2   673572  \n",
       "3   151266  \n",
       "4    93351  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df = pd.read_csv(\"datasets/cleaned_anime.csv\")\n",
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With collaborative filtering, we actually don't need a lot of the animes' metadata as the recommendations are primarily dictated by the users who have watched a certain anime and not the actual contents. This contrasts with content based filtering which uses the anime information to predict what a user would like. As a result of this, we can remove a lot of information that we don't need from the anime data both to make the process clearer and save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama째</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32935</td>\n",
       "      <td>Haikyuu!!: Karasuno Koukou VS Shiratorizawa Ga...</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                                               name  rating\n",
       "0      5114                   Fullmetal Alchemist: Brotherhood    9.26\n",
       "1     28977                                           Gintama째    9.25\n",
       "2      9253                                        Steins;Gate    9.17\n",
       "3      9969                                      Gintama&#039;    9.16\n",
       "4     32935  Haikyuu!!: Karasuno Koukou VS Shiratorizawa Ga...    9.15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove information we don't need\n",
    "anime_df = anime_df.loc[:, [\"anime_id\", \"name\", \"rating\"]]\n",
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Dataset\n",
    "Read in the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  anime_id  rating\n",
       "0        1        20     NaN\n",
       "1        1        24     NaN\n",
       "2        1        79     NaN\n",
       "3        1       226     NaN\n",
       "4        1       241     NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv(\"datasets/cleaned_rating.csv\")\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing to do for the ratings data is to remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "anime_id    0\n",
       "rating      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values\n",
    "rating_df.dropna(inplace=True)\n",
    "# How many missing values do we have?\n",
    "rating_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Recommendation System\n",
    "To build the collaborative filtering system, I will be using a sample user input from animes I have watched in the past. To build it, I will be using the SciKit Surprise library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 175 ms, total: 2.09 s\n",
      "Wall time: 2.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x2d3d985b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Import the surprise library\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "\n",
    "# reader parses the file containing the ratings\n",
    "# Our rating scale is from 1 to 10 inclusive\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "# Load the dataframe into the model's dataset\n",
    "data = Dataset.load_from_df(rating_df[[\"user_id\", \"anime_id\", \"rating\"]], reader)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our rating data loaded into surprise, we can create our collaborative filtering system. For this, I decided to use the famous SVD algorithm that is included with surprise. I will also be using surprise's GridSearchCV which is very similar to sklearn's GridSearchCV to find the best parameters for the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SVD algorithm\n",
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV to tune parameters\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:14\u001b[0m\n",
      "File \u001b[0;32m~/Downloads/University of Windsor/Sem-2/Database/Project/Anime-Project/env/lib/python3.10/site-packages/surprise/model_selection/search.py:104\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     90\u001b[0m cv \u001b[39m=\u001b[39m get_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv)\n\u001b[1;32m     92\u001b[0m delayed_list \u001b[39m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m     delayed(fit_and_score)(\n\u001b[1;32m     94\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgo_class(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m out \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    105\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    106\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpre_dispatch,\n\u001b[1;32m    107\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjoblib_verbose,\n\u001b[1;32m    108\u001b[0m )(delayed_list)\n\u001b[1;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mout)\n\u001b[1;32m    112\u001b[0m \u001b[39m# test_measures_dicts is a list of dict like this:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# E.g. for 5 splits, the first 5 dicts are for the first param\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m# (n_parameters_combinations, n_splits). This way we can easily compute\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m# the mean and std dev over all splits or over all param comb.\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/University of Windsor/Sem-2/Database/Project/Anime-Project/env/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Downloads/University of Windsor/Sem-2/Database/Project/Anime-Project/env/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Downloads/University of Windsor/Sem-2/Database/Project/Anime-Project/env/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.7/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.7/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This cell took a LONG time to run on my computer\n",
    "# Don't suggest running it unless you have time to waste\n",
    "\n",
    "\n",
    "\n",
    "# Create parameters combinations\n",
    "params = {\n",
    "    \"n_epochs\": [10, 15], \"lr_all\": [0.003, 0.005, 0.007], \"reg_all\": [0.01, 0.02, 0.03]\n",
    "}\n",
    "\n",
    "# Run the grid search using SVD and the parameters to find the best parameters for Root Mean Square Error and Mean Absolute Error\n",
    "gs = GridSearchCV(SVD, params, measures=['rmse', 'mae'], cv=3, joblib_verbose=2, n_jobs=-2)\n",
    "\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Best RMSE score\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(gs\u001b[39m.\u001b[39mbest_score[\u001b[39m\"\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39m# Best combination of parameters for the best RMSE\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(gs\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score'"
     ]
    }
   ],
   "source": [
    "# Best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# Best combination of parameters for the best RMSE\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best parameters from the GridSearchCV we ran, we can now set our recommendation algorithm to the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as far as my Google searches and tutorials got me. What I suspect is that using `algo.predict(user_id, anime_id).est` I can get the estimated rating that the user would give for that specific anime. Perhaps if I made a numpy array that stored the estimated ratings for a number of animes for a given user, I could find the ones with the highest estimated ratings and recommend those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.01538233688656"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just testing out the prediction method on user 4271 on anime id 7088\n",
    "pred = algo.predict(4271, 7088).est\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing to do is to export the recommendation system into a Pickle file for potentially usage in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dump function\n",
    "from surprise.dump import dump\n",
    "# Create the Pickle file for the SVD algorithm\n",
    "dump(\"recommender.pkl\", algo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2193276bb69ddbf6a522d2a88a5dce39db93896d69d16b23aa8361ef3f2cc6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
